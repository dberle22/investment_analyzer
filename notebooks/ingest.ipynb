{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8e33e-6d8c-4e72-991e-d730d7d0d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment Research ‚Äî Ingestion Notebook (No Caching)\n",
    "\n",
    "# This notebook lets you:\n",
    "# 1. Define tickers and a date range\n",
    "# 2. Download **daily prices** (tidy format)\n",
    "# 3. Download **full raw fundamentals** for each ticker\n",
    "# 4. Save outputs under `data/raw/prices/` and `data/raw/fundamentals/`\n",
    "# 5. Inspect results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603c31df-bcba-4e62-920d-83f9df470da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook CWD: /Users/danberle/Documents/projects/investment_analyzer/scripts\n",
      "DATA_DIR: /Users/danberle/Documents/projects/investment_analyzer/data/raw\n",
      "Project root: /Users/danberle/Documents/projects/investment_analyzer\n",
      "PRICES_DIR: /Users/danberle/Documents/projects/investment_analyzer/data/raw/prices\n",
      "FUNDS_DIR: /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports and Paths ----\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from yahooquery import Ticker\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# Method 1: Using pathlib.Path throughout (recommended)\n",
    "NB_CWD = Path.cwd()\n",
    "PROJECT_ROOT = NB_CWD.parent\n",
    "DATA_DIR = NB_CWD.parent / 'data' / 'raw'\n",
    "PRICES_DIR = DATA_DIR / \"prices\"\n",
    "FUNDS_DIR = DATA_DIR / \"fundamentals\"\n",
    "\n",
    "# Create directories using Path objects\n",
    "for d in (DATA_DIR, PRICES_DIR, FUNDS_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Notebook CWD:\", NB_CWD)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"PRICES_DIR:\", PRICES_DIR)\n",
    "print(\"FUNDS_DIR:\", FUNDS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf6531a-4ebe-4dd2-ab68-bffa1bad39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Download Prices Function ----\n",
    "def get_prices(tickers, start: str, end: str, interval: str = \"1d\", save: bool = True, auto_adjust: bool = False):\n",
    "    \"\"\"\n",
    "    Download tidy daily OHLCV for a list of tickers by looping single-ticker requests.\n",
    "    Returns one long/tidy DataFrame and (optionally) writes per-ticker CSVs.\n",
    "    \n",
    "    Args:\n",
    "        tickers: List of ticker symbols or single ticker string\n",
    "        start: Start date in YYYY-MM-DD format\n",
    "        end: End date in YYYY-MM-DD format\n",
    "        interval: Data interval (default \"1d\")\n",
    "        save: Whether to save individual CSV files\n",
    "        auto_adjust: Whether to auto-adjust prices\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined tidy DataFrame with all ticker data\n",
    "    \"\"\"\n",
    "    # Ensure tickers is a list\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    all_prices = []\n",
    "    ordered_columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"ticker\"]\n",
    "    \n",
    "    for tk in tickers:\n",
    "        try:\n",
    "            print(f\"üìà Downloading {tk}...\")\n",
    "            \n",
    "            # Download data for single ticker to avoid MultiIndex issues\n",
    "            df = yf.download(\n",
    "                tk, \n",
    "                start=start, \n",
    "                end=end, \n",
    "                interval=interval,\n",
    "                auto_adjust=auto_adjust,\n",
    "                progress=False  # Suppress progress bar for cleaner output\n",
    "            )\n",
    "            \n",
    "            # Handle empty DataFrame\n",
    "            if df.empty:\n",
    "                print(f\"‚ö†Ô∏è  No data found for {tk}\")\n",
    "                continue\n",
    "            \n",
    "            # Reset index to make Date a column\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            # Handle potential MultiIndex columns (flatten if necessary)\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = [col[0] if col[1] == tk or col[1] == '' else f\"{col[0]}_{col[1]}\" \n",
    "                             for col in df.columns]\n",
    "            \n",
    "            # Ensure column names are clean\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            # Add ticker column\n",
    "            df[\"ticker\"] = tk\n",
    "            \n",
    "            # Standardize Date column name (yfinance sometimes returns 'Datetime')\n",
    "            if 'Datetime' in df.columns:\n",
    "                df = df.rename(columns={'Datetime': 'Date'})\n",
    "            \n",
    "            # Keep only columns that exist in our ordered list\n",
    "            available_columns = [c for c in ordered_columns if c in df.columns]\n",
    "            df = df[available_columns]\n",
    "            \n",
    "            # Ensure Date is datetime type\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "            \n",
    "            # Sort by date\n",
    "            if 'Date' in df.columns:\n",
    "                df = df.sort_values('Date')\n",
    "            \n",
    "            # Save individual CSV if requested\n",
    "            if save:\n",
    "                clean_start = start.replace('-', '')\n",
    "                clean_end = end.replace('-', '')\n",
    "                filename = f\"{tk.lower()}_{clean_start}_{clean_end}_{interval}.csv\"\n",
    "                filepath = PRICES_DIR / filename\n",
    "                df.to_csv(filepath, index=False)\n",
    "                print(f\"‚úÖ Saved {len(df)} records for {tk} ‚Üí {filename}\")\n",
    "            \n",
    "            all_prices.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading {tk}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    if all_prices:\n",
    "        combined = pd.concat(all_prices, ignore_index=True)\n",
    "        # Sort by ticker and date for better organization\n",
    "        if 'Date' in combined.columns and 'ticker' in combined.columns:\n",
    "            combined = combined.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"üéâ Successfully combined data for {len(combined['ticker'].unique())} tickers, {len(combined)} total records\")\n",
    "        return combined\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No data was successfully downloaded\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dd5a97-3d44-4659-a1aa-6bf4251141e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Download Prices Function (yahooquery - RECOMMENDED) ----\n",
    "def get_prices(tickers, start: str, end: str, interval: str = \"1d\", save: bool = True):\n",
    "    \"\"\"\n",
    "    Download tidy daily OHLCV for a list of tickers using yahooquery.\n",
    "    Returns one long/tidy DataFrame and (optionally) writes per-ticker CSVs.\n",
    "    \n",
    "    Args:\n",
    "        tickers: List of ticker symbols or single ticker string\n",
    "        start: Start date in YYYY-MM-DD format\n",
    "        end: End date in YYYY-MM-DD format\n",
    "        interval: Data interval (default \"1d\")\n",
    "        save: Whether to save individual CSV files\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined tidy DataFrame with all ticker data\n",
    "    \"\"\"\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    all_prices = []\n",
    "    ordered_columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"ticker\"]\n",
    "    \n",
    "    for tk in tickers:\n",
    "        try:\n",
    "            print(f\"üìà Downloading {tk}...\")\n",
    "            \n",
    "            ticker_obj = Ticker(tk)\n",
    "            df = ticker_obj.history(start=start, end=end, interval=interval)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(f\"‚ö†Ô∏è  No data found for {tk}\")\n",
    "                continue\n",
    "            \n",
    "            # Reset index to get date as column\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            # Add ticker column\n",
    "            df[\"ticker\"] = tk\n",
    "            \n",
    "            # Rename columns to match standard format\n",
    "            column_mapping = {\n",
    "                'date': 'Date',\n",
    "                'open': 'Open', \n",
    "                'high': 'High',\n",
    "                'low': 'Low',\n",
    "                'close': 'Close',\n",
    "                'adjclose': 'Adj Close',\n",
    "                'volume': 'Volume'\n",
    "            }\n",
    "            df = df.rename(columns=column_mapping)\n",
    "            \n",
    "            # Keep only available columns\n",
    "            available_columns = [c for c in ordered_columns if c in df.columns]\n",
    "            df = df[available_columns]\n",
    "            \n",
    "            # Ensure Date is datetime\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df = df.sort_values('Date')\n",
    "            \n",
    "            if save:\n",
    "                clean_start = start.replace('-', '')\n",
    "                clean_end = end.replace('-', '')\n",
    "                filename = f\"{tk.lower()}_{clean_start}_{clean_end}_{interval}.csv\"\n",
    "                filepath = PRICES_DIR / filename\n",
    "                df.to_csv(filepath, index=False)\n",
    "                print(f\"‚úÖ Saved {len(df)} records for {tk} ‚Üí {filename}\")\n",
    "            \n",
    "            all_prices.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading {tk}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if all_prices:\n",
    "        combined = pd.concat(all_prices, ignore_index=True)\n",
    "        if 'Date' in combined.columns and 'ticker' in combined.columns:\n",
    "            combined = combined.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"üéâ Successfully combined data for {len(combined['ticker'].unique())} tickers, {len(combined)} total records\")\n",
    "        return combined\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No data was successfully downloaded\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ---- Fallback using yfinance (if needed) ----\n",
    "def get_prices_yfinance_fallback(tickers, start: str, end: str, interval: str = \"1d\", save: bool = True):\n",
    "    \"\"\"\n",
    "    Fallback function using yfinance if yahooquery fails.\n",
    "    \"\"\"\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    \n",
    "    all_prices = []\n",
    "    ordered_columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\", \"ticker\"]\n",
    "    \n",
    "    for tk in tickers:\n",
    "        try:\n",
    "            print(f\"üìà Downloading {tk} via yahooquery...\")\n",
    "            \n",
    "            ticker_obj = Ticker(tk)\n",
    "            df = ticker_obj.history(start=start, end=end, interval=interval)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(f\"‚ö†Ô∏è  No data found for {tk}\")\n",
    "                continue\n",
    "            \n",
    "            # Reset index to get date as column\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            # Add ticker column\n",
    "            df[\"ticker\"] = tk\n",
    "            \n",
    "            # Rename columns to match yfinance format\n",
    "            column_mapping = {\n",
    "                'date': 'Date',\n",
    "                'open': 'Open', \n",
    "                'high': 'High',\n",
    "                'low': 'Low',\n",
    "                'close': 'Close',\n",
    "                'adjclose': 'Adj Close',\n",
    "                'volume': 'Volume'\n",
    "            }\n",
    "            df = df.rename(columns=column_mapping)\n",
    "            \n",
    "            # Keep only available columns\n",
    "            available_columns = [c for c in ordered_columns if c in df.columns]\n",
    "            df = df[available_columns]\n",
    "            \n",
    "            # Ensure Date is datetime\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df = df.sort_values('Date')\n",
    "            \n",
    "            if save:\n",
    "                clean_start = start.replace('-', '')\n",
    "                clean_end = end.replace('-', '')\n",
    "                filename = f\"{tk.lower()}_{clean_start}_{clean_end}_{interval}_yq.csv\"\n",
    "                filepath = PRICES_DIR / filename\n",
    "                df.to_csv(filepath, index=False)\n",
    "                print(f\"‚úÖ Saved {len(df)} records for {tk} ‚Üí {filename}\")\n",
    "            \n",
    "            all_prices.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading {tk}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if all_prices:\n",
    "        combined = pd.concat(all_prices, ignore_index=True)\n",
    "        if 'Date' in combined.columns and 'ticker' in combined.columns:\n",
    "            combined = combined.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"üéâ Successfully combined data for {len(combined['ticker'].unique())} tickers, {len(combined)} total records\")\n",
    "        return combined\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162c09d2-44c7-48ba-8bd3-464582805e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helper Functions for Fundamentals ----\n",
    "def _safe_get_block(block, ticker):\n",
    "    \"\"\"\n",
    "    yahooquery properties (price, summary_detail, etc.) may be dict, DataFrame, or None.\n",
    "    Return a dict-like (or basic Python structure) for JSON serialization.\n",
    "    \"\"\"\n",
    "    # Most of these properties are dicts keyed by ticker\n",
    "    if isinstance(block, dict):\n",
    "        return block.get(ticker)\n",
    "    # Some versions may return a pandas object or list-like; convert if needed\n",
    "    if hasattr(block, \"to_dict\"):\n",
    "        try:\n",
    "            return block.to_dict()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return block  # could be None or plain type\n",
    "\n",
    "def _safe_stmt(callable_fn):\n",
    "    \"\"\"\n",
    "    Statement methods (income_statement/balance_sheet/cash_flow) vary by version.\n",
    "    Try a few signatures and return a dict keyed by ticker OR a serializable structure.\n",
    "    \"\"\"\n",
    "    for args in ((), ()):\n",
    "        for kwargs in ({}, {\"trailing\": False}):\n",
    "            try:\n",
    "                return callable_fn(*args, **kwargs)\n",
    "            except TypeError:\n",
    "                continue\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def _flatten_fundamentals_dict(ticker: str, raw_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"Light flatten for a quick one-row preview (deep cleaning happens later).\"\"\"\n",
    "    rows = {\"ticker\": ticker, \"as_of\": raw_dict.get(\"as_of\")}\n",
    "    for block in [\"price\", \"summary_detail\", \"key_stats\", \"financial_data\", \"asset_profile\"]:\n",
    "        b = raw_dict.get(block)\n",
    "        if isinstance(b, dict):\n",
    "            pref = f\"{block}.\"\n",
    "            rows.update({pref + k: v for k, v in b.items()})\n",
    "    return pd.DataFrame([rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4731e330-d551-49a7-ac13-2ab69107b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Fundamentals Functions ----\n",
    "def download_fundamentals_raw(ticker: str, save_json: bool = True, save_flat_csv: bool = True):\n",
    "    t = Ticker(ticker)\n",
    "\n",
    "    # property blocks\n",
    "    price            = _safe_get_block(getattr(t, \"price\", None), ticker) if hasattr(t, \"price\") else None\n",
    "    summary_detail   = _safe_get_block(getattr(t, \"summary_detail\", None), ticker) if hasattr(t, \"summary_detail\") else None\n",
    "    key_stats        = _safe_get_block(getattr(t, \"key_stats\", None), ticker) if hasattr(t, \"key_stats\") else None\n",
    "    financial_data   = _safe_get_block(getattr(t, \"financial_data\", None), ticker) if hasattr(t, \"financial_data\") else None\n",
    "    asset_profile    = _safe_get_block(getattr(t, \"asset_profile\", None), ticker) if hasattr(t, \"asset_profile\") else None\n",
    "    earnings         = _safe_get_block(getattr(t, \"earnings\", None), ticker) if hasattr(t, \"earnings\") else None\n",
    "\n",
    "    # statement blocks (may be dict keyed by ticker or something else)\n",
    "    income_stmt_raw  = _safe_stmt(getattr(t, \"income_statement\", lambda: None)) if hasattr(t, \"income_statement\") else None\n",
    "    balance_raw      = _safe_stmt(getattr(t, \"balance_sheet\", lambda: None))    if hasattr(t, \"balance_sheet\")    else None\n",
    "    cashflow_raw     = _safe_stmt(getattr(t, \"cash_flow\", lambda: None))        if hasattr(t, \"cash_flow\")        else None\n",
    "\n",
    "    # Extract this ticker's piece if we got dicts keyed by ticker\n",
    "    if isinstance(income_stmt_raw, dict):\n",
    "        income_stmt_raw = income_stmt_raw.get(ticker)\n",
    "    if isinstance(balance_raw, dict):\n",
    "        balance_raw = balance_raw.get(ticker)\n",
    "    if isinstance(cashflow_raw, dict):\n",
    "        cashflow_raw = cashflow_raw.get(ticker)\n",
    "\n",
    "    # If any of those are pandas objects, convert to serializable records\n",
    "    def to_serializable(obj):\n",
    "        if hasattr(obj, \"to_dict\"):\n",
    "            try:\n",
    "                return obj.to_dict(orient=\"records\")\n",
    "            except TypeError:\n",
    "                return obj.to_dict()\n",
    "        return obj\n",
    "\n",
    "    raw = {\n",
    "        \"as_of\": datetime.today().strftime(\"%Y-%m-%d\"),\n",
    "        \"price\": price,\n",
    "        \"summary_detail\": summary_detail,\n",
    "        \"key_stats\": key_stats,\n",
    "        \"financial_data\": financial_data,\n",
    "        \"asset_profile\": asset_profile,\n",
    "        \"earnings\": earnings,\n",
    "        \"income_statement\": to_serializable(income_stmt_raw),\n",
    "        \"balance_sheet\": to_serializable(balance_raw),\n",
    "        \"cash_flow\": to_serializable(cashflow_raw),\n",
    "    }\n",
    "\n",
    "    if save_json:\n",
    "        asof = datetime.today().strftime(\"%Y%m%d\")\n",
    "        raw_fp = FUNDS_DIR / f\"{ticker.lower()}_fundamentals_raw_{asof}.json\"\n",
    "        with raw_fp.open(\"w\") as f:\n",
    "            json.dump(raw, f, indent=2, default=str)\n",
    "        print(f\"‚úÖ Saved RAW fundamentals for {ticker} ‚Üí {raw_fp}\")\n",
    "\n",
    "    flat = _flatten_fundamentals_dict(ticker, raw)\n",
    "    if save_flat_csv:\n",
    "        snap_fp = FUNDS_DIR / f\"{ticker.lower()}_fundamentals_flat_{datetime.today().strftime('%Y%m%d')}.csv\"\n",
    "        flat.to_csv(snap_fp, index=False)\n",
    "        print(f\"üìÑ Saved flattened snapshot for {ticker} ‚Üí {snap_fp}\")\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d0c210-db2a-45eb-8f38-d26462186ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['AAPL', 'MSFT', 'GOOGL'], '2020-01-01', '2025-08-12', '1d')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Parameters ----\n",
    "# Edit as you like\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "interval = \"1d\"\n",
    "\n",
    "tickers, start_date, end_date, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af134207-7023-4925-ad4f-91e1e38a09b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Downloading AAPL...\n",
      "‚úÖ Saved 1409 records for AAPL ‚Üí aapl_20200101_20250812_1d.csv\n",
      "üéâ Successfully combined data for 1 tickers, 1409 total records\n",
      "üìà Downloading MSFT...\n",
      "‚úÖ Saved 1409 records for MSFT ‚Üí msft_20200101_20250812_1d.csv\n",
      "üéâ Successfully combined data for 1 tickers, 1409 total records\n",
      "üìà Downloading GOOGL...\n",
      "‚úÖ Saved 1409 records for GOOGL ‚Üí googl_20200101_20250812_1d.csv\n",
      "üéâ Successfully combined data for 1 tickers, 1409 total records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4227, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Prices loop (independent; won't block fundamentals if one fails)\n",
    "price_results = []\n",
    "for tk in tickers:\n",
    "    try:\n",
    "        dfp = get_prices([tk], start_date, end_date, interval, save=True)\n",
    "        price_results.append(dfp)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Price fetch failed for {tk}: {e}\")\n",
    "\n",
    "prices_df = pd.concat(price_results, ignore_index=True) if price_results else pd.DataFrame()\n",
    "\n",
    "prices_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703bd16f-b26f-4ed9-b6c3-905817ce74fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved combined data: combined_prices_20200101_20250812.csv\n",
      "üìä Total records: 4227\n",
      "üìà Tickers: AAPL, MSFT, GOOGL\n"
     ]
    }
   ],
   "source": [
    "# Save combined CSV with simplified naming\n",
    "if not prices_df.empty:\n",
    "    clean_start = start_date.replace('-', '')\n",
    "    clean_end = end_date.replace('-', '')\n",
    "    \n",
    "    combined_filename = f\"combined_prices_{clean_start}_{clean_end}.csv\"\n",
    "    combined_filepath = PRICES_DIR / combined_filename\n",
    "    \n",
    "    prices_df.to_csv(combined_filepath, index=False)\n",
    "    print(f\"‚úÖ Saved combined data: {combined_filename}\")\n",
    "    print(f\"üìä Total records: {len(prices_df)}\")\n",
    "    print(f\"üìà Tickers: {', '.join(prices_df['ticker'].unique())}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to save - combined DataFrame is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634b569b-c34f-41f8-8641-f4861ba0e40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved RAW fundamentals for AAPL ‚Üí /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals/aapl_fundamentals_raw_20250812.json\n",
      "üìÑ Saved flattened snapshot for AAPL ‚Üí /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals/aapl_fundamentals_flat_20250812.csv\n",
      "‚úÖ Saved RAW fundamentals for MSFT ‚Üí /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals/msft_fundamentals_raw_20250812.json\n",
      "üìÑ Saved flattened snapshot for MSFT ‚Üí /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals/msft_fundamentals_flat_20250812.csv\n",
      "‚úÖ Saved RAW fundamentals for GOOGL ‚Üí /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals/googl_fundamentals_raw_20250812.json\n",
      "üìÑ Saved flattened snapshot for GOOGL ‚Üí /Users/danberle/Documents/projects/investment_analyzer/data/raw/fundamentals/googl_fundamentals_flat_20250812.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 178)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Fundamentals loop (independent)\n",
    "fund_results = []\n",
    "for tk in tickers:\n",
    "    try:\n",
    "        dff = download_fundamentals_raw(tk, save_json=True, save_flat_csv=True)\n",
    "        fund_results.append(dff)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fundamentals fetch failed for {tk}: {e}\")\n",
    "\n",
    "funds_df = pd.concat(fund_results, ignore_index=True) if fund_results else pd.DataFrame()\n",
    "\n",
    "funds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6800ac50-49ac-4d51-8adc-c38e7fc59eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved combined data: combined_fundamentals_20250812.csv\n",
      "üìä Total records: 3\n",
      "üìà Tickers: AAPL, MSFT, GOOGL\n"
     ]
    }
   ],
   "source": [
    "# Save combined CSV with simplified naming\n",
    "if not funds_df.empty:\n",
    "    clean_date = end_date.replace('-', '')\n",
    "    \n",
    "    combined_filename = f\"combined_fundamentals_{clean_date}.csv\"\n",
    "    combined_filepath = FUNDS_DIR / combined_filename\n",
    "    \n",
    "    funds_df.to_csv(combined_filepath, index=False)\n",
    "    print(f\"‚úÖ Saved combined data: {combined_filename}\")\n",
    "    print(f\"üìä Total records: {len(funds_df)}\")\n",
    "    print(f\"üìà Tickers: {', '.join(funds_df['ticker'].unique())}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to save - combined DataFrame is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47562c4c-cd7e-4ccd-bc11-8606b981df7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>73.797501</td>\n",
       "      <td>75.087502</td>\n",
       "      <td>72.538521</td>\n",
       "      <td>135480400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>74.287498</td>\n",
       "      <td>75.144997</td>\n",
       "      <td>74.125000</td>\n",
       "      <td>74.357498</td>\n",
       "      <td>71.833298</td>\n",
       "      <td>146322800</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.447502</td>\n",
       "      <td>74.989998</td>\n",
       "      <td>73.187500</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>72.405678</td>\n",
       "      <td>118387200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>74.959999</td>\n",
       "      <td>75.224998</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>72.065147</td>\n",
       "      <td>108872000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>76.110001</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>75.797501</td>\n",
       "      <td>73.224403</td>\n",
       "      <td>132079200</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>76.809998</td>\n",
       "      <td>77.607498</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>77.407501</td>\n",
       "      <td>74.779732</td>\n",
       "      <td>170108400</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>77.650002</td>\n",
       "      <td>78.167503</td>\n",
       "      <td>77.062500</td>\n",
       "      <td>77.582497</td>\n",
       "      <td>74.948776</td>\n",
       "      <td>140644800</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>77.910004</td>\n",
       "      <td>79.267502</td>\n",
       "      <td>77.787498</td>\n",
       "      <td>79.239998</td>\n",
       "      <td>76.550041</td>\n",
       "      <td>121532000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close  \\\n",
       "0 2020-01-02  74.059998  75.150002  73.797501  75.087502  72.538521   \n",
       "1 2020-01-03  74.287498  75.144997  74.125000  74.357498  71.833298   \n",
       "2 2020-01-06  73.447502  74.989998  73.187500  74.949997  72.405678   \n",
       "3 2020-01-07  74.959999  75.224998  74.370003  74.597504  72.065147   \n",
       "4 2020-01-08  74.290001  76.110001  74.290001  75.797501  73.224403   \n",
       "5 2020-01-09  76.809998  77.607498  76.550003  77.407501  74.779732   \n",
       "6 2020-01-10  77.650002  78.167503  77.062500  77.582497  74.948776   \n",
       "7 2020-01-13  77.910004  79.267502  77.787498  79.239998  76.550041   \n",
       "\n",
       "      Volume ticker  \n",
       "0  135480400   AAPL  \n",
       "1  146322800   AAPL  \n",
       "2  118387200   AAPL  \n",
       "3  108872000   AAPL  \n",
       "4  132079200   AAPL  \n",
       "5  170108400   AAPL  \n",
       "6  140644800   AAPL  \n",
       "7  121532000   AAPL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>as_of</th>\n",
       "      <th>price.maxAge</th>\n",
       "      <th>price.preMarketChangePercent</th>\n",
       "      <th>price.preMarketChange</th>\n",
       "      <th>price.preMarketTime</th>\n",
       "      <th>price.preMarketPrice</th>\n",
       "      <th>price.preMarketSource</th>\n",
       "      <th>price.postMarketChangePercent</th>\n",
       "      <th>price.postMarketChange</th>\n",
       "      <th>...</th>\n",
       "      <th>asset_profile.auditRisk</th>\n",
       "      <th>asset_profile.boardRisk</th>\n",
       "      <th>asset_profile.compensationRisk</th>\n",
       "      <th>asset_profile.shareHolderRightsRisk</th>\n",
       "      <th>asset_profile.overallRisk</th>\n",
       "      <th>asset_profile.governanceEpochDate</th>\n",
       "      <th>asset_profile.compensationAsOfEpochDate</th>\n",
       "      <th>asset_profile.irWebsite</th>\n",
       "      <th>asset_profile.executiveTeam</th>\n",
       "      <th>asset_profile.maxAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005326</td>\n",
       "      <td>-1.209992</td>\n",
       "      <td>2025-08-12 05:29:40</td>\n",
       "      <td>225.97</td>\n",
       "      <td>FREE_REALTIME</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>-0.921097</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-07-31 20:00:00</td>\n",
       "      <td>2024-12-30 19:00:00</td>\n",
       "      <td>http://investor.apple.com/</td>\n",
       "      <td>[]</td>\n",
       "      <td>86400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>1.505005</td>\n",
       "      <td>2025-08-12 05:29:17</td>\n",
       "      <td>523.42</td>\n",
       "      <td>FREE_REALTIME</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.574951</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-07-31 20:00:00</td>\n",
       "      <td>2024-12-30 19:00:00</td>\n",
       "      <td>http://www.microsoft.com/investor/default.aspx</td>\n",
       "      <td>[]</td>\n",
       "      <td>86400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.130005</td>\n",
       "      <td>2025-08-12 05:29:10</td>\n",
       "      <td>200.87</td>\n",
       "      <td>FREE_REALTIME</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>-0.350006</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-07-31 20:00:00</td>\n",
       "      <td>2024-12-30 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>86400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       as_of  price.maxAge  price.preMarketChangePercent  \\\n",
       "0   AAPL  2025-08-12             1                     -0.005326   \n",
       "1   MSFT  2025-08-12             1                      0.002884   \n",
       "2  GOOGL  2025-08-12             1                     -0.000647   \n",
       "\n",
       "   price.preMarketChange  price.preMarketTime  price.preMarketPrice  \\\n",
       "0              -1.209992  2025-08-12 05:29:40                225.97   \n",
       "1               1.505005  2025-08-12 05:29:17                523.42   \n",
       "2              -0.130005  2025-08-12 05:29:10                200.87   \n",
       "\n",
       "  price.preMarketSource  price.postMarketChangePercent  \\\n",
       "0         FREE_REALTIME                      -0.004054   \n",
       "1         FREE_REALTIME                       0.001102   \n",
       "2         FREE_REALTIME                      -0.001741   \n",
       "\n",
       "   price.postMarketChange  ... asset_profile.auditRisk  \\\n",
       "0               -0.921097  ...                       7   \n",
       "1                0.574951  ...                       9   \n",
       "2               -0.350006  ...                       7   \n",
       "\n",
       "   asset_profile.boardRisk asset_profile.compensationRisk  \\\n",
       "0                        1                              3   \n",
       "1                        5                              4   \n",
       "2                        9                             10   \n",
       "\n",
       "   asset_profile.shareHolderRightsRisk  asset_profile.overallRisk  \\\n",
       "0                                    1                          1   \n",
       "1                                    2                          3   \n",
       "2                                   10                         10   \n",
       "\n",
       "  asset_profile.governanceEpochDate  asset_profile.compensationAsOfEpochDate  \\\n",
       "0               2025-07-31 20:00:00                      2024-12-30 19:00:00   \n",
       "1               2025-07-31 20:00:00                      2024-12-30 19:00:00   \n",
       "2               2025-07-31 20:00:00                      2024-12-30 19:00:00   \n",
       "\n",
       "                          asset_profile.irWebsite  \\\n",
       "0                      http://investor.apple.com/   \n",
       "1  http://www.microsoft.com/investor/default.aspx   \n",
       "2                                             NaN   \n",
       "\n",
       "   asset_profile.executiveTeam  asset_profile.maxAge  \n",
       "0                           []                 86400  \n",
       "1                           []                 86400  \n",
       "2                           []                 86400  \n",
       "\n",
       "[3 rows x 178 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick Preview\n",
    "display(prices_df.head(8))\n",
    "display(funds_df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
